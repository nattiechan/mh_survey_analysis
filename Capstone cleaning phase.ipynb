{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project\n",
    "-------\n",
    "\n",
    "### Stage 1 - Cleaning phase\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing packages and data\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nattiechan/anaconda3/envs/myenv/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn import pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used for this project is from the [2017](https://www.kaggle.com/osmihelp/osmi-mental-health-in-tech-survey-2017) and [2018](https://www.kaggle.com/osmihelp/osmi-mental-health-in-tech-survey-2018) Mental Health in the Tech Industry conducted by Open Sourcing Mental Illness (OSMI), available on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data_2017 = pd.read_csv(\"Datasets/2017_survey.csv\")\n",
    "data_2018 = pd.read_csv(\"Datasets/2018_survey.csv\")\n",
    "\n",
    "# Combing the datasets to one table\n",
    "data = pd.concat([data_2017,data_2018],sort=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminary data cleaning\n",
    "------\n",
    "\n",
    "<u> Goals: </u>\n",
    "\n",
    "1. Cleaning column titles\n",
    "2. Combining and cleaning responses\n",
    "3. Handling NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some functions for use later on\n",
    "def combine_columns(first_num,num_list,df_name):\n",
    "    '''\n",
    "    This function combines duplicate columns.\n",
    "    \n",
    "    Inputs:\n",
    "    ------\n",
    "    first_num: an integer of the column number you wish the information to be combined to\n",
    "    num_list: a list of integers of the column numbers you wish the information to be combined\n",
    "    df_name = the name of the dataframe\n",
    "    \n",
    "    '''\n",
    "    for num in num_list:\n",
    "        df_name.iloc[:,first_num] = df_name.iloc[:,first_num] + df_name.iloc[:,num]\n",
    "\n",
    "def combine_info(my_list,column_name = \"What is your race?\"):\n",
    "    '''\n",
    "    This function combines similar responses (but spelled differently or used slightly different wording) \n",
    "    into one category of response.\n",
    "    \n",
    "    Inputs:\n",
    "    ------\n",
    "    my_list = a list of responses you want to put into the category\n",
    "    column_name = the name of the column\n",
    "    \n",
    "    '''\n",
    "    for num,info in enumerate(my_list):\n",
    "        if num > 0:\n",
    "            df[column_name][df[column_name]==info] = my_list[0]\n",
    "            \n",
    "def fillna_with_median(question = \"What is your age?\"):\n",
    "    '''\n",
    "    This function fills NaN values with the median of the column.\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    question: the name of the column\n",
    "    \n",
    "    '''\n",
    "    median = np.median(df[question][df[question].isna()==False])\n",
    "    df[question].fillna(median,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the questions have HTML code embedded in them, so come cleaning is required to ease the searching process later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning column titles\n",
    "columns_to_clean = data.columns[data.columns.str.contains(\"<strong>\")]\n",
    "\n",
    "# grouping column names based on where the HTML code is at\n",
    "list_1 = (columns_to_clean[:7],columns_to_clean[9:11])\n",
    "list_2 = (columns_to_clean[-5],columns_to_clean[-3])\n",
    "list_3 = (columns_to_clean[-4],columns_to_clean[-2])\n",
    "list_4 = [[\"If you have a mental health disorder, how often do you feel that it interferes with your work <strong>when being treated effectively?</strong>\",\n",
    "            \"If you have a mental health disorder, how often do you feel that it interferes with your work when being treated effectively?\"],\n",
    "           [\"If you have a mental health disorder, how often do you feel that it interferes with your work <strong>when <em>NOT</em> being treated effectively (i.e., when you are experiencing symptoms)?</strong>\",\n",
    "            \"If you have a mental health disorder, how often do you feel that it interferes with your work when NOT being treated effectively (i.e., when you are experiencing symptoms)?\"]]\n",
    "\n",
    "# renaming columns\n",
    "for item in list_1:\n",
    "    for question in range(len(item)):\n",
    "        data.rename(columns = {f\"{item[question]}\": f\"{item[question][8:-9]}\"},inplace=True)\n",
    "\n",
    "for question in list_2:\n",
    "    data.rename(columns = {f\"{question}\": f\"{question[:20]+question[28:32]+question[-4:]}\"},inplace=True)\n",
    "\n",
    "for question in list_3:\n",
    "    data.rename(columns = {f\"{question}\": f\"{question[:34]+question[42:46]+question[-4:]}\"},inplace=True)\n",
    "\n",
    "for pairs in list_4:\n",
    "    data.rename(columns = {pairs[0]:pairs[1]},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique indexes are created to label each row of the survey data which replaces the IDs under the column `#`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert unique id and drop column \"#\"\n",
    "data.insert(0,\"id\",(data.index+1))\n",
    "data.drop(columns = \"#\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning responses for MH disorders\n",
    "-----\n",
    "\n",
    "The columns for MH disorders from different years have not been combined. Therefore, the results will be combined and the duplicates will be deleted.\n",
    "\n",
    "First, the information in the duplicated columns will be combined to the first 13 columns of MH disorders avoid loss of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combining data\n",
    "start_num = 50\n",
    "\n",
    "while start_num < 64:\n",
    "    data.iloc[:,start_num].fillna(data.iloc[:,(start_num+13)],inplace=True)\n",
    "    data.iloc[:,start_num].fillna(data.iloc[:,(start_num+26)],inplace=True)\n",
    "    data.iloc[:,start_num].fillna(0,inplace=True)\n",
    "    data.iloc[:,start_num].where(data.iloc[:,start_num]==0,1,inplace=True)\n",
    "    start_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disorders in the \"Other\" category will be converted to dummy variables to match the format of other columns of MH disorders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking number of entries in each column\n",
    "others_dummy = pd.concat([pd.get_dummies(data[\"Other.1\"]),pd.get_dummies(data[\"Other.2\"])],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some disorders like Asperger's Syndrome are repeated with slightly different names, those columns will be combined to avoid duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining columns\n",
    "ADHD_list = (5,8)\n",
    "ASD_list = (1,2,3,7,9)\n",
    "Depression_list = (15,16)\n",
    "\n",
    "my_list = [(0,ADHD_list),(10,ASD_list),(14,Depression_list)]\n",
    "\n",
    "for num, name in my_list:\n",
    "    combine_columns(num,name,others_dummy)\n",
    "\n",
    "# combining panic disorder\n",
    "others_dummy.iloc[:,-3] = others_dummy.iloc[:,-3] + others_dummy.iloc[:,-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the information from the duplicate columns are combined, the duplicates in the DataFrame `others_dummy` can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicate columns in others_dummy\n",
    "drop_list = list(ADHD_list + ASD_list + Depression_list)\n",
    "drop_list.append(20)\n",
    "column_names = []\n",
    "\n",
    "for num in drop_list:\n",
    "    column_names.append(others_dummy.columns[num])\n",
    "\n",
    "others_dummy.drop(columns = column_names,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon further inspection, some responses in the \"Other\" category are duplicates of existing categories in the main dataset (eg. Mood Disorder). The responses will therefore be added to the main dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mood disorder\n",
    "data.iloc[:,51] = data.iloc[:,51] + others_dummy.iloc[:,-5] + others_dummy.iloc[:,4]\n",
    "\n",
    "# ADHD\n",
    "data.iloc[:,54] += others_dummy.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, those duplicate columns in `others_dummy` will be dropped as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_list = (0,4,7)\n",
    "column_names2 = []\n",
    "\n",
    "for num in drop_list:\n",
    "    column_names2.append(others_dummy.columns[num])\n",
    "\n",
    "others_dummy.drop(columns = column_names2,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the information from all the \"Other\" category have been extracted, all the duplicate columns can now be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicate columns in data\n",
    "data.drop(columns=data.columns[62:89],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handling duplicate columns for other questions\n",
    "-----\n",
    "\n",
    "There are also some survey questions that appear to have duplicate columns. Those are questions on:\n",
    "\n",
    "- How would team members react to your MH diagnoses\n",
    "- How the MH disorder interfering with work when it is not treated properly\n",
    "- Current employer's MH coverage\n",
    "\n",
    "Also, the last column of the data is irrelvant to the analysis so the column will be dropped as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(5,-4),(66,-3),(76,-2)]\n",
    "\n",
    "for i,j in pairs:\n",
    "    data.iloc[:,i].fillna(data.iloc[:,j],inplace=True)\n",
    "    data.drop(columns=data.columns[j],inplace=True)\n",
    "\n",
    "# drop last column in data\n",
    "data.drop(columns=data.columns[-1],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handling NaN values and combining responses\n",
    "------\n",
    "\n",
    "NaN values are handled in the following ways:\n",
    "\n",
    "- The column will be dropped if there are more than 50% NaN values or there are more than 25% NaN value but they will not be used for the modelling phase\n",
    "- In most text responses, NaN values will be replaced with \"did not answer\" or \"NA\"\n",
    "- In most categorical responses (i.e 0/1), NaN values will be replaced with -1\n",
    "- In most continuous responses, NaN values will be replaced with either the median value or filled using machine learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining df\n",
    "data = pd.concat([data.iloc[:,:62], others_dummy, data.iloc[:,62:]],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a copy of the dataset\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in some NaN for some columns that have over 50% NaN value to keep those columns\n",
    "for num in [49,-6]:\n",
    "    df.iloc[:,num].fillna(\"Did not answer\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with over 50% NaN values\n",
    "delete_list = df.isna().sum()[df.isna().sum() > 587]\n",
    "\n",
    "for num in range(len(delete_list)):\n",
    "    df.drop(columns = delete_list.index[num],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop columns with over 25% NaN values that are deemed not essential\n",
    "df.drop(columns=df.columns[-12],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna for describing things to improve\n",
    "df.iloc[:,-12].fillna(\"Did not answer\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning race column\n",
    "question = \"What is your race?\"\n",
    "df[question].fillna(df[\"Other.3\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up the responses\n",
    "hispanics = [\"Hispanic\",\"Hispanic or Latino\",\"Latina\",\"Latino\",\"Latinx\",\"mexican american \"]\n",
    "no_answer = [\"Did not answer\",\"I prefer not to answer\",\"I am of the race of Adam, the first human.\"]\n",
    "mixed = [\"Mixed\",\"More than one of the above\",\"Hispanic, White\",\"Mestizo\"]\n",
    "jewish = [\"Jewish\",\"Ashkenazi\"]\n",
    "caucasian = [\"Caucasian\",\"White\",\"European American\",\"My race is white, but my ethnicity is Latin American\"]\n",
    "caribbean = [\"Caribbean\",\"Indo-Caribbean\",\"West Indian\"]\n",
    "asian = [\"Asian\",\"South Asian\"]\n",
    "aa = [\"Afrcian American\",\"Black or African American\"]\n",
    "\n",
    "race_list = [hispanics,no_answer,mixed,jewish,caucasian,caribbean,asian,aa]\n",
    "\n",
    "for race in race_list:\n",
    "    combine_info(race,column_name = \"What is your race?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicate column\n",
    "df.drop(columns=\"Other.3\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning gender\n",
    "question = \"What is your gender?\"\n",
    "\n",
    "df[question].fillna(\"Did not answer\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine gender responses\n",
    "male = [\"Male\",\"Cis Male\",\"Cis male\",\"Cis-male\",\"Cisgender male\",\"M\",\"MALE\",\"cis hetero male\",\"cis male\",\n",
    "        \"cis male \",\"cis-male\",\"dude\",\"m\",\"male\",\"male (hey this is the tech industry you're talking about)\",\n",
    "        \"male, born with xy chromosoms\",\"male/androgynous\",\"man\",\"God King of the Valajar\",\"Mail\",\"Male \",\n",
    "        \"Male (cis)\",\"Male, cis\",\"SWM\",\"Malel\",\"Man\",\"Ostensibly Male\"]\n",
    "\n",
    "female = [\"Female\",\"*shrug emoji* (F)\",\"Cis female \",\"Cis woman\",\"Cis-Female\",\"Cisgendered woman\",\"F\",\n",
    "          \"F, cisgender\",\"Female \",\"Female (cis) \",\"Female (cisgender)\",\"I identify as female\",\"Woman\",\n",
    "          \"Woman-identified\",\"cis female\",\"cis-Female\",\"cisgender female\",\"f\",\"femail\",\"female\",\n",
    "          \"female (cis)\",\"female (cisgender)\",\"femalw\",\"woman\",\"My sex is female.\"]\n",
    "\n",
    "genderqueer = [\"Genderqueer\",\"Agender\",\"Agender/genderfluid\",\"Contextual\",\"Female-ish\",\"Demiguy\",\n",
    "               \"Female/gender non-binary.\",\"Genderfluid\",\"Genderqueer demigirl\",\"Genderqueer/non-binary\",\n",
    "               \"Male (or female, or both)\",\"Male-ish\",\"NB\",\"Non binary\",\"Non-binary\",\"Nonbinary\",\n",
    "               \"Nonbinary/femme\",\"She/her/they/them\",\"gender non-conforming woman\",\"genderfluid\",\n",
    "               \"non binary\",\"non-binary\",\"nonbinary\",\"uhhhhhhhhh fem genderqueer?\",\"male/androgynous \"]\n",
    "\n",
    "transgender = [\"Transgender\",\"Trans female\",\"Trans man\",\"Trans woman\",\"Transfeminine\",\n",
    "               \"trans woman\",\"transgender\"]\n",
    "\n",
    "other = [\"Other\",\"None\",\"\\-\",\"none\",\"sometimes\"]\n",
    "\n",
    "gender_list = [male,female,genderqueer,transgender,other]\n",
    "\n",
    "for gender in gender_list:\n",
    "    combine_info(gender,column_name = \"What is your gender?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up # of employees\n",
    "question = \"How many employees does your company or organization have?\"\n",
    "\n",
    "df[question].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# grabbing a list of participants who are self-employed\n",
    "self_employed = df[df[question]==0].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check and see if # NaN = 169 are all from self-employed participants\n",
    "my_list = df.isna().sum().index[df.isna().sum()==169]\n",
    "index_list = list(my_list.values)\n",
    "\n",
    "for i,j in enumerate(index_list):\n",
    "    b = df[index_list[i]][df[index_list[i]].isna()==True].index.values\n",
    "    print(np.bincount(self_employed == b))\n",
    "\n",
    "# looks like all these are from the self-employed group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# changing NaN values in columns with text data to NA\n",
    "my_list = df.isna().sum().index[5:13]\n",
    "column_list = list(my_list.values)\n",
    "column_list.append(df.isna().sum().index[14])\n",
    "\n",
    "for question in column_list:\n",
    "    df.loc[(self_employed),column_list]=\"Not Applicable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaNs in age and overall rating with median\n",
    "fillna_with_median(question = \"What is your age?\")\n",
    "fillna_with_median(question = \"Overall, how well do you think the tech industry supports employees with mental health issues?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Network ID as a clue to fill in a NaN value\n",
    "df[df[\"What country do you live in?\"].isna()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Network ID as a clue to fill in a NaN value\n",
    "df.loc[755,\"What country do you live in?\"]=\"Did not answer\"\n",
    "\n",
    "for num in [-8,-5]:\n",
    "    df.iloc[753,num]=\"United States of America\"\n",
    "    \n",
    "for num in [-7,-4]:\n",
    "    df.iloc[753,num]=\"Indiana\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in NaN values for US states\n",
    "df[\"What US state or territory do you live in?\"].fillna(\"NA\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns\n",
    "df.drop(columns = df.columns[-5:-3],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filling some NaN with -1 - indicating did not answer\n",
    "my_list = df.isna().sum()[df.isna().sum() > 1].index\n",
    "positions = [0,1,3,4,5,8,-3,-4,-7,-8,-11,-12,-14]\n",
    "\n",
    "for i in positions:\n",
    "    df.loc[:,my_list[i]].fillna(-1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filling in the missing values in overall ratings using machine learning algorithm\n",
    "------\n",
    "\n",
    "<u>Independent variables:</u> \n",
    "- Gender\n",
    "- Country of residence\n",
    "- Race\n",
    "\n",
    "<u>Dependent variable:</u>\n",
    "- Respective overall ratings\n",
    "\n",
    "<u>Models considered:</u>\n",
    "- Decision Tree Classifier\n",
    "- Random Forrest Classifier\n",
    "- XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of questions with overall ratings\n",
    "rating_list = df.isna().sum().index[df.isna().sum().index.str.contains(\"Overall\")].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating independent and dependent variables for the model\n",
    "original = {}\n",
    "final = {}\n",
    "train = {}\n",
    "test = {}\n",
    "\n",
    "for num in range(len(rating_list)-1):\n",
    "    original[num] = df.loc[:,(rating_list[num],\"What is your gender?\",\"What country do you live in?\",\n",
    "                              \"What is your race?\")]\n",
    "    \n",
    "    dummies = pd.get_dummies(original[num].iloc[:,1:])\n",
    "    final[num] = pd.concat([original[num].iloc[:,0],dummies],axis=1)\n",
    "\n",
    "    train[num] = final[num][final[num].iloc[:,0].isna()==False]\n",
    "    test[num] = final[num][final[num].iloc[:,0].isna()==True]\n",
    "\n",
    "#overall industry ratings need to be dealt with separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using GridsearchCV to determine the optimum model for each rating\n",
    "\n",
    "# to filter deprecation warning associated with numpy\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "for num in range(len(rating_list)-1):\n",
    "    x = train[num].iloc[:,1:]\n",
    "    y = train[num].iloc[:,0]\n",
    "    x_test = test[num].iloc[:,1:]\n",
    "\n",
    "    estimators = [('model', DecisionTreeClassifier())]\n",
    "\n",
    "    pipe = pipeline.Pipeline(estimators)\n",
    "\n",
    "    param_grid = [{'model': [DecisionTreeClassifier()]},\n",
    "                  {'model': [RandomForestClassifier()]},\n",
    "                  {'model': [XGBClassifier()]}]\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "    grid_search = grid.fit(x, y)\n",
    "    print(num,grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on results from GridSearchCV, Decision Tree Classifier is best for the first question on the list and XGB Classifier is the best for the rest of the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filling in the NaN values\n",
    "for num in range(len(rating_list)-1):\n",
    "    x = train[num].iloc[:,1:]\n",
    "    y = train[num].iloc[:,0]\n",
    "    x_test = test[num].iloc[:,1:]\n",
    "\n",
    "    if num == 0:\n",
    "        dt = DecisionTreeClassifier()\n",
    "        # 5-fold cross-validated to be the best one out of the box\n",
    "\n",
    "        dt.fit(x,y)\n",
    "        results = dt.predict(x_test)\n",
    "    \n",
    "    else:\n",
    "        xgb = XGBClassifier()\n",
    "        # 5-fold cross-validated to be the best one out of the box\n",
    "\n",
    "        xgb.fit(x,y)\n",
    "        results = xgb.predict(x_test)\n",
    "    \n",
    "    values = df.loc[:,rating_list[num]][df[rating_list[num]].isna()==True].index.values\n",
    "\n",
    "    for position, value in enumerate(values):\n",
    "        df.loc[value,rating_list[num]] = results[position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in more NaN values\n",
    "column_list = df.isna().sum()[df.isna().sum() > 1].index\n",
    "\n",
    "for column in column_list:\n",
    "    df.loc[:,column].fillna(\"Did not answer\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simplify responses for MH disorders\n",
    "------\n",
    "\n",
    "Responses will be grouped into broader categories to aid in modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining responses\n",
    "neuro = [\"Attention Deficit Hyperactivity Disorder\",\"Autism Spectrum Disorder\",\"Tourette's\"]\n",
    "adjust = [\"Adjustment disorder\",\"Stress Response Syndromes\"]\n",
    "substance = [\"Substance Use Disorder\",\"Addictive Disorder\"]\n",
    "anxiety = [\"Anxiety Disorder (Generalized, Social, Phobia, etc)\",\"Panic Disorder\"]\n",
    "mood = [\"Mood Disorder (Depression, Bipolar Disorder, etc)\",\"Cyclothymia\"]\n",
    "other = ['Suicidal','Codependence','Gender Dysphoria', 'Multiple Sclerosis & Mental Health']\n",
    "\n",
    "column_list = [neuro,adjust,substance,anxiety,mood,other]\n",
    "\n",
    "for var in column_list:\n",
    "    for num,column in enumerate(var):\n",
    "        if num > 0:\n",
    "            df.loc[:,var[0]] += df.loc[:,var[num]]\n",
    "            df.drop(columns = var[num],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming some columns\n",
    "\n",
    "my_list = [[\"Attention Deficit Hyperactivity Disorder\",\"Neurodevelopmental Disorders\"],\n",
    "           [\"Substance Use Disorder\",\"Substance-Related and Addictive Disorders\"],\n",
    "           [\"Suicidal\",\"Other\"],\n",
    "           [\"Anxiety Disorder (Generalized, Social, Phobia, etc)\",\"Anxiety Disorder\"],\n",
    "           [\"Mood Disorder (Depression, Bipolar Disorder, etc)\",\"Mood Disorder\"],\n",
    "           [\"Psychotic Disorder (Schizophrenia, Schizoaffective, etc)\",\"Psychotic Disorder\"],\n",
    "           [\"Eating Disorder (Anorexia, Bulimia, etc)\",\"Eating Disorder\"],\n",
    "           [\"Personality Disorder (Borderline, Antisocial, Paranoid, etc)\",\"Personality Disorder\"]]\n",
    "\n",
    "for pairs in my_list:\n",
    "    df.rename(columns = {pairs[0] : pairs[1]},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replacing some duplicate responds since the answers are binary (0/1)\n",
    "for num in range(36,48):\n",
    "    df.iloc[:,num].replace(2,1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced cleaning\n",
    "------\n",
    "\n",
    "Model-specific data cleaning and preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying and grouping some of the answers\n",
    "question = \"Would you have been willing to discuss your mental health with your coworkers at previous employers?\"\n",
    "old_answer = \"At some of my previous employers\"\n",
    "new_answer = \"Some of my previous employers\"\n",
    "\n",
    "df.loc[:,question][df.loc[:,question]==old_answer]=new_answer\n",
    "\n",
    "new_name = \"Does your employer provide mental health benefits as part of healthcare coverage?\"\n",
    "\n",
    "df.rename(columns = {df.columns[5] : new_name}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying and grouping some of the answers\n",
    "question_1 = \"Does your employer provide mental health benefits as part of healthcare coverage?\"\n",
    "question_2 = \"Do you know the options for mental health care available under your employer-provided health coverage?\"\n",
    "question_3 = \"Have you observed or experienced an unsupportive or badly handled response to a mental health issue in your current or previous workplace?\"\n",
    "question_4 = \"Have you observed or experienced supportive or well handled response to a mental health issue in your current or previous workplace?\"\n",
    "\n",
    "answer_1 = \"Not Applicable\"\n",
    "answer_2 = \"Not eligible for coverage / NA\"\n",
    "answer_3 = \"Did not answer\"\n",
    "answer_4 = \"Yes, I experienced\"\n",
    "answer_5 = \"Yes, I observed\"\n",
    "answer_6 = \"Yes\"\n",
    "\n",
    "df.loc[:,question_1][df.loc[:,question_1]==answer_1]=answer_2\n",
    "\n",
    "df.loc[:,question_2][df.loc[:,question_2]==answer_3]=answer_1\n",
    "\n",
    "for question in [question_3,question_4]:\n",
    "    df.loc[:,question][df.loc[:,question]==answer_4]=answer_5\n",
    "    df.loc[:,question][df.loc[:,question]==answer_5]=answer_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cleaned dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Please continue to the notebook *Capstone modelling stage final* for the remainder of the project.\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
