{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project\n",
    "-------\n",
    "\n",
    "### Stage 2 - Modelling phase\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing packages and data\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible packages that need to be installed:\n",
    "\n",
    "1. SpaCy\n",
    "\n",
    "<code> conda install -c spacy spacy </code>\n",
    "\n",
    "2. 'en_core_web_md' - library used in SpaCy\n",
    "\n",
    "<code> python -m spacy download en_core_web_md </code>\n",
    "\n",
    "3. WordCloud\n",
    "\n",
    "<code> conda install -c conda-forge wordcloud </code>\n",
    "\n",
    "4. Hyperas\n",
    "\n",
    "<code> conda install -c jaikumarm hyperas </code>\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "# Hyperas/TensorFlow\n",
    "# the __future__ import command must be in the beginning of the notebook\n",
    "from __future__ import print_function\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from tensorflow.python.keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Basics\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Graphs\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "# Preprocessing; model selection and evaluation\n",
    "from sklearn import pipeline, preprocessing\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# text handling\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# for custom countvectorizer with SpaCy lemmatization\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, VectorizerMixin\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# WordCloud\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "data = pd.read_csv(\"saved_csv/df.csv\")\n",
    "data.drop(columns = \"Unnamed: 0\",inplace=True)\n",
    "\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "------\n",
    "\n",
    "Below outlines the questions to be answered with the cleaned data, and proposed methodology for each question.\n",
    "\n",
    "<b><i><u>Question #1</b></i></u>\n",
    "\n",
    "**What are some of the qualitative insights for the tech industry to improve MH support for employees?**\n",
    "\n",
    "In the survey, there is a question asking participants to briefly describe what the industry can do as a whole to improve mental health (MH) support for their employees. The purpose of the analysis is to see whether there are any *underlying themes or patterns* to the responses.\n",
    "\n",
    "<i><u>Methodology</i></u>\n",
    "\n",
    "Process the text using *SpaCy Lemmatizer* and *CountVectorizer*, then visualize the patterns using *WordCloud*. Since the font on the WordCloud is based on the frequency of the words appearing in the entire dataset, the more frequently used words will be larger in the WordCloud, suggesting a pattern or theme.\n",
    "\n",
    "<b><i><u>Question #2</b></i></u>\n",
    "\n",
    "**What are the factors that affect comfort level in discussing MH at workplace?**\n",
    "\n",
    "One proposed hypothesis is that improving comfort level in discussing MH at workplace can contribute to improving MH support for employees in the tech industry. A *prescriptive analysis* will be done to determine the factors using various questions pertaining to employer's MH coverage, personal MH status and experience with having MH conversations at the workplace, and overall perceived ratings in the dataset as features.\n",
    "\n",
    "<i><u>Methodology</i></u>\n",
    "\n",
    "Determine the statistical significance of each feature and the model as a whole using *Statsmodels Logistic Regression*, then use either *Random Forrest Classifier* or *XGBoost Classifier* to determine feature importance.\n",
    "\n",
    "<b><i><u>Question #3</b></i></u>\n",
    "\n",
    "**Can we predict one's comfort level in discussing MH at workplace using participants' qualitative responses of ways to improve MH support?**\n",
    "\n",
    "A *predictive model* will be built to determine if the qualitative responses are viable predictors of one's comfort level in discussing MH at workplace.\n",
    "\n",
    "<i><u>Methodology</i></u>\n",
    "\n",
    "Design a model using a *Recurrent Neural Network (RNN)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "------\n",
    "\n",
    "#### Independent Variables for Q2\n",
    "------\n",
    "\n",
    "Questions will be grouped into one of the following categories:\n",
    "\n",
    "- Current employer's MH coverage\n",
    "- Previous employer's MH coverage\n",
    "- MH status\n",
    "- Witnessed experience (of discussing MH in the workplace)\n",
    "- Overall perceived ratings\n",
    "- Comfort level discussing MH in the workplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting questions into categories\n",
    "\n",
    "current_mh_coverage = [\"Does your employer provide mental health benefits as part of healthcare coverage?\",\n",
    "               \"Do you know the options for mental health care available under your employer-provided health coverage?\",\n",
    "               \"Has your employer ever formally discussed mental health (for example, as part of a wellness campaign or other official communication)?\",\n",
    "               \"Does your employer offer resources to learn more about mental health disorders and options for seeking help?\",\n",
    "               \"Is your anonymity protected if you choose to take advantage of mental health or substance abuse treatment resources provided by your employer?\",\n",
    "               \"If a mental health issue prompted you to request a medical leave from work, how easy or difficult would it be to ask for that leave?\"]\n",
    "\n",
    "previous_mh_coverage = [\"Have your previous employers provided mental health benefits?\",\n",
    "                        \"Were you aware of the options for mental health care provided by your previous employers?\",\n",
    "                        \"Did your previous employers ever formally discuss mental health (as part of a wellness campaign or other official communication)?\",\n",
    "                        \"Did your previous employers provide resources to learn more about mental health disorders and how to seek help?\",\n",
    "                        \"Was your anonymity protected if you chose to take advantage of mental health or substance abuse treatment resources with previous employers?\"]\n",
    "\n",
    "mh_status = [\"Do you currently have a mental health disorder?\",\n",
    "             \"Have you ever been diagnosed with a mental health disorder?\",'Anxiety Disorder', 'Mood Disorder', \n",
    "             'Psychotic Disorder','Eating Disorder', 'Neurodevelopmental Disorders','Personality Disorder', \n",
    "             'Obsessive-Compulsive Disorder','Post-Traumatic Stress Disorder', 'Dissociative Disorder',\n",
    "             'Substance-Related and Addictive Disorders', 'Other','Adjustment disorder',\n",
    "             \"Have you had a mental health disorder in the past?\",\n",
    "             \"Have you ever sought treatment for a mental health disorder from a mental health professional?\",\n",
    "             \"Do you have a family history of mental illness?\",\n",
    "             \"How willing would you be to share with friends and family that you have a mental illness?\",\n",
    "             \"Would you be willing to bring up a physical health issue with a potential employer in an interview?\"]\n",
    "\n",
    "witnessed_exp = [\"Have your observations of how another individual who discussed a mental health issue made you less likely to reveal a mental health issue yourself in your current workplace?\",\n",
    "                 \"Have you observed or experienced an unsupportive or badly handled response to a mental health issue in your current or previous workplace?\",\n",
    "                 \"Have you observed or experienced supportive or well handled response to a mental health issue in your current or previous workplace?\"]\n",
    "\n",
    "ratings = df.columns[df.columns.str.contains(\"Overall\")]\n",
    "\n",
    "demographics = [\"What is your age?\",\"What is your gender?\",\"What country do you live in?\",\n",
    "                \"What US state or territory do you live in?\",\"What is your race?\"]\n",
    "\n",
    "comfort_talking_current = [\"Would you feel comfortable discussing a mental health issue with your direct supervisor(s)?\",\n",
    "                           \"Have you ever discussed your mental health with your employer?\",\n",
    "                           \"Would you feel comfortable discussing a mental health issue with your coworkers?\",\n",
    "                           \"Have you ever discussed your mental health with coworkers?\",\n",
    "                           \"Have you ever had a coworker discuss their or another coworker's mental health with you?\",\n",
    "                           \"Would you feel more comfortable talking to your coworkers about your physical health or your mental health?\",\n",
    "                           \"Would you bring up your mental health with a potential employer in an interview?\",\n",
    "                           \"Are you openly identified at work as a person with a mental health issue?\"]\n",
    "\n",
    "comfort_talking_previous = [\"Would you have felt more comfortable talking to your previous employer about your physical health or your mental health?\",\n",
    "                            \"Would you have been willing to discuss your mental health with your direct supervisor(s)?\",\n",
    "                            \"Did you ever discuss your mental health with your previous employer?\",\n",
    "                            \"Would you have been willing to discuss your mental health with your coworkers at previous employers?\",\n",
    "                            \"Did you ever discuss your mental health with a previous coworker(s)?\",\n",
    "                            \"Did you ever have a previous coworker discuss their or another coworker's mental health with you?\",\n",
    "                            \"Would you bring up your mental health with a potential employer in an interview?\",\n",
    "                            \"Are you openly identified at work as a person with a mental health issue?\"]\n",
    "\n",
    "categories = [current_mh_coverage,previous_mh_coverage,mh_status,witnessed_exp,\n",
    "              ratings,comfort_talking_current,comfort_talking_previous]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various questions from current employer's MH coverage, MH status, witnessed experience as well as overall perceived ratings will be chosen as indpendent variables. Demographic data such as age, country of residence and race will be included for generaliability of the results.\n",
    "\n",
    "Dummy variables will be generated from the responses of each question. Responses will be grouped in two general categories (eg. Yes/No) and for the independent variables, one group of responses will be dropped to avoid multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating functions for dummy generation\n",
    "def make_dummies(question,columns_to_keep = \"Yes\"):\n",
    "    '''\n",
    "    The function creates dummy variables for independent variables.\n",
    "    You can specify the column to KEEP.\n",
    "    \n",
    "    Inputs:\n",
    "    ------\n",
    "    question: the question/column name that you wish to create a dummy vairable for\n",
    "    columns_to_keep: a string indicating the answer you want to keep\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    result: a DataFrame of the desire column in dummy variables.\n",
    "    '''\n",
    "    \n",
    "    dummies = pd.get_dummies(df_2.loc[:,question])\n",
    "    for j in range(len(dummies.columns)):\n",
    "        name = question + \"__\" + columns_to_keep\n",
    "        dummies.rename(columns = {columns_to_keep : name},inplace=True)\n",
    "\n",
    "    result = dummies.loc[:,[name]]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def make_dummies_iloc(question,list_to_keep):\n",
    "    '''\n",
    "    The function creates dummy variables for independent variables.\n",
    "    This is designed for instances when you need to keep multiple responses.\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    question: the question/column name that you wish to create a dummy variable for\n",
    "    list_to_keep: a list of numbers corresponding the column numbers of the responses \n",
    "                  (after it has been converted to dummy variables) that you want to keep\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    result: A DataFrame of the desire column in dummy variables.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    dummies = pd.get_dummies(df_2.loc[:,question])\n",
    "    for j in range(len(dummies.columns)):\n",
    "        name = question + \"__\" + dummies.columns[j]\n",
    "        dummies.rename(columns = {dummies.columns[j] : name},inplace=True)\n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "    for num in list_to_keep:\n",
    "        to_keep = dummies.iloc[:,num]\n",
    "        result = pd.concat([result,to_keep],axis=1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def make_dummies_q(column_num,column_name):\n",
    "    '''\n",
    "    This function creates a dummy variable for a particular column,\n",
    "    and drops a column to avoid multicollinearity since the responses will be included in the independent variables.\n",
    "    \n",
    "    Inputs:\n",
    "    ------\n",
    "    column_num = an integer of the number of column/question you wish to create a dummy variable for\n",
    "    column_name = the response that you wish to drop to avoid multicollinearity\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    result = a DataFrame of dummy variables, containing n-1 answers\n",
    "    '''\n",
    "\n",
    "    result = pd.get_dummies(df_2.iloc[:,column_num])\n",
    "    result.drop(columns = column_name, inplace=True)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a copy of the data\n",
    "df_2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up 2 dataframes for concatenating data\n",
    "omitted = pd.DataFrame(columns = [\"Question\",\"Answer\"])\n",
    "final = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# current_mh_coverage\n",
    "for i in [0,2,3]:\n",
    "    result = make_dummies(current_mh_coverage[i],\"Yes\")\n",
    "    final = pd.concat([final,result],axis = 1)\n",
    "\n",
    "result = make_dummies_iloc(current_mh_coverage[5],[2,-2,-1])\n",
    "final = pd.concat([final,result],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# witnessed_exp\n",
    "result = make_dummies(witnessed_exp[0],\"Yes\")\n",
    "final = pd.concat([final,result],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mh_status\n",
    "\n",
    "# Modifying some responses for ease of sorting\n",
    "old_answer_1 = \"Possibly\"\n",
    "old_answer_2 = \"-1\"\n",
    "answer = \"Don't Know\"\n",
    "\n",
    "to_dummy = []\n",
    "for i in [0,1,-5,-3,-1]:\n",
    "    to_dummy.append(mh_status[i])\n",
    "\n",
    "for num in [0,2]:\n",
    "    df_2.loc[:,to_dummy[num]][df_2.loc[:,to_dummy[num]]==old_answer_1]=answer\n",
    "\n",
    "df_2.loc[:,to_dummy[2]][df_2.loc[:,to_dummy[2]]==old_answer_2]=answer\n",
    "\n",
    "#creating dummy variables\n",
    "result = make_dummies(to_dummy[0],\"Yes\")\n",
    "final = pd.concat([final,result],axis = 1)\n",
    "\n",
    "for i in [2,3,4,5,6,7,8,9,10,11,12,13,15,17]:\n",
    "    final = pd.concat([final,df_2.loc[:,mh_status[i]]],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings\n",
    "for i in [1,4]:\n",
    "    final = pd.concat([final,df_2.loc[:,ratings[i]]],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What is your gender?\n",
    "gender = make_dummies_q(-7,\"Male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping countries into 5 continents\n",
    "country_names = df_2.iloc[:,-6].groupby(df_2.iloc[:,-6]).count().index\n",
    "\n",
    "df_2[\"countries_continent\"] = df_2.iloc[:,-6]\n",
    "\n",
    "north_am = [8,34,55]\n",
    "south_am = [0,6,9,56]\n",
    "asia = [3,20,23,24,26,28,29,39,43,44,46]\n",
    "africa = [14,30,33,37,48]\n",
    "europe = [2,4,5,7,10,11,13,15,16,17,18,19,21,22,25,27,31,32,35,38,40,41,42,45,47,49,50,51,52,53,54]\n",
    "oceania = [1,36]\n",
    "did_not_answer = [12]\n",
    "\n",
    "continents = [north_am,south_am,asia,africa,europe,oceania,did_not_answer]\n",
    "names = [\"North America\", \"South America\", \"Asia\", \"Africa\", \"Europe\", \"Oceania\", \"Did not answer\"]\n",
    "\n",
    "for position,continent in enumerate(continents):\n",
    "    for num in np.flip(continent):\n",
    "        df_2.loc[:,\"countries_continent\"][df_2.loc[:,\"countries_continent\"]== country_names[num]]=names[position]\n",
    "        \n",
    "countries = make_dummies_q(-1,\"North America\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is your race?\n",
    "races = make_dummies_q(-5,\"Did not answer\")\n",
    "for num in range(-4,0):\n",
    "    races.drop(columns = [races.columns[num]],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_size\n",
    "company_size = make_dummies_q(2,\"0\")\n",
    "\n",
    "# select companies with larger size into the independent variables\n",
    "size = company_size.iloc[:,[3,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a table of demographics\n",
    "demographics = pd.concat([gender,countries,races,size,df_2.iloc[:,[-9,1,3,4]]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalizing the table of independent variables with demographics\n",
    "independent_q1 = pd.concat([final,demographics],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependent Variables for Q2\n",
    "------\n",
    "\n",
    "Various questions from questions from comfort level of discussing MH in the workplace will be chosen as the dependent variable.\n",
    "\n",
    "Dummy variables will be generated from the responses of each question. Clusters of classes will be created afterwards with unsupervised clustering methods using the dummy variables as independent variables. In contrast to the independent variable, all responses can be kept since there is no issue of multicollinearity with dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Would you feel comfortable discussing a mental health issue with your coworkers?\"\n",
    "\n",
    "answers = [\"Maybe\",\"No\",\"Not Applicable\",\"Yes\"]\n",
    "\n",
    "dep = df_2[question].copy()\n",
    "\n",
    "for num in range(len(answers)):\n",
    "    if num != 3:\n",
    "        dep[dep==answers[num]] = 0 #Hesitant\n",
    "    else:\n",
    "        dep[dep==answers[num]] = 1 #Comfortable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Would you feel comfortable discussing a mental health issue with your direct supervisor(s)?\"\n",
    "\n",
    "answers = [\"Maybe\",\"No\",\"Not Applicable\",\"Yes\"]\n",
    "\n",
    "dep_2 = df_2[question].copy()\n",
    "\n",
    "for num in range(len(answers)):\n",
    "    if num != 3:\n",
    "        dep_2[dep_2==answers[num]] = 0 #Hesitant\n",
    "    else:\n",
    "        dep_2[dep_2==answers[num]] = 1 #Comfortable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "### What are some of the qualitative insights for the tech industry to improve MH support for employees?\n",
    "-----\n",
    "\n",
    "Qualitative responses from the question \"briefly describe what you think the industry as a whole and/or employers could do to improve mental health support for employees\" will be processed using [spacy-vectorizers](https://github.com/mpavlovic/spacy-vectorizers), a custom CountVectorizer with SpaCy lemmatization embedded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spacy-vectorizers to process texts\n",
    "# Code source: https://github.com/mpavlovic/spacy-vectorizers\n",
    "\n",
    "class SpacyPipeInitializer(object):\n",
    "    def __init__(self, nlp, join_str=\" \", batch_size=10000, n_threads=2):\n",
    "        self.nlp = nlp\n",
    "        self.join_str = join_str\n",
    "        self.batch_size = batch_size\n",
    "        self.n_threads = n_threads\n",
    "        \n",
    "class SpacyPipeProcessor(SpacyPipeInitializer):\n",
    "    def __init__(self, nlp, multi_iters=False, join_str=\" \", batch_size=10000, n_threads=2):\n",
    "        super(SpacyPipeProcessor, self).__init__(nlp, join_str, batch_size, n_threads)\n",
    "        self.multi_iters = multi_iters\n",
    "    \n",
    "    def __call__(self, raw_documents):\n",
    "        docs_generator = self.nlp.pipe(raw_documents, batch_size=self.batch_size, n_threads=self.n_threads)\n",
    "        return docs_generator if self.multi_iters == False else list(docs_generator)\n",
    "    \n",
    "class SpacyLemmaCountVectorizer(CountVectorizer):\n",
    "    \n",
    "    def __init__(self, input='content', encoding='utf-8',\n",
    "                 decode_error='strict', strip_accents=None,\n",
    "                 lowercase=True, preprocessor=None, tokenizer=None,\n",
    "                 stop_words=None, token_pattern=r\"(?u)[^\\r\\n ]+\",\n",
    "                 ngram_range=(1, 1), analyzer='word',\n",
    "                 max_df=1.0, min_df=1, max_features=None,\n",
    "                 vocabulary=None, binary=False, dtype=np.int64, \n",
    "                 nlp=None, ignore_chars='!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~', \n",
    "                 join_str=\" \", use_pron=False):\n",
    "        \n",
    "        super().__init__(input, encoding, decode_error, strip_accents, \n",
    "                                                   lowercase, preprocessor, tokenizer,\n",
    "                                                   stop_words, token_pattern, ngram_range, \n",
    "                                                   analyzer, max_df, min_df, max_features,\n",
    "                                                   vocabulary, binary, dtype)\n",
    "        self.ignore_chars = ignore_chars\n",
    "        self.join_str = ' ' # lemmas have to be joined for splitting\n",
    "        self.use_pron = use_pron\n",
    "        self.translate_table = dict((ord(char), None) for char in self.ignore_chars)\n",
    "        \n",
    "    def lemmatize_from_docs(self, docs):\n",
    "        for doc in docs:\n",
    "            lemmas_gen = (token.lemma_.translate(self.translate_table) if self.use_pron or token.lemma_!='-PRON-' else token.lower_.translate(self.translate_table) for token in doc)  # generator expression\n",
    "            yield self.join_str.join(lemmas_gen) if self.join_str is not None else [lemma for lemma in lemmas_gen]\n",
    "    \n",
    "    def build_tokenizer(self):\n",
    "        return lambda doc: doc.split()\n",
    "    \n",
    "    def transform(self, spacy_docs):\n",
    "        raw_documents = self.lemmatize_from_docs(spacy_docs)\n",
    "        return super(SpacyLemmaCountVectorizer, self).transform(raw_documents)\n",
    "    \n",
    "    def fit_transform(self, spacy_docs, y=None):\n",
    "        raw_documents = self.lemmatize_from_docs(spacy_docs)\n",
    "        return super(SpacyLemmaCountVectorizer, self).fit_transform(raw_documents, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grabbing the text responses\n",
    "corpus = df.iloc[:,-9]\n",
    "\n",
    "# customization stopwords to filter out some words\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"mental\",\"health\",\"issue\",\"work\",\n",
    "                  \"take\",\"hour\",\"tech\",\"industry\",\"people\",\"employee\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer with SpaCy Lemmatization\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "spp = SpacyPipeProcessor(nlp, n_threads=1, multi_iters=True)\n",
    "spacy_docs = spp(corpus);\n",
    "\n",
    "slcv = SpacyLemmaCountVectorizer(min_df=3,stop_words=stopwords, ngram_range=(1, 3), ignore_chars='!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
    "slcv.fit(spacy_docs)\n",
    "count_vectors = slcv.transform(spacy_docs); count_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the text has been processed, a WordCloud is generated to visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pulling out the list of parsed words and put them into a wordcloud\n",
    "list_of_words = slcv.vocabulary_.keys()\n",
    "list_of_words = list(list_of_words)\n",
    "list_of_words.sort()\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\").generate(\" \".join(list_of_words))\n",
    "\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words with bigger fonts in the WordCloud are ones that occur in the dataset with higher frequency. From the WordCloud above, it seems like words like \"open\", \"support\", \"talk\" are big themes of the responses. This finding supports the need of looking deeper into factos that affect comfort level in discussing MH in the workplace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question #2\n",
    "\n",
    "### What are the factors that affect comfort level in discussing MH at workplace?\n",
    "------\n",
    "\n",
    "#### a) Comfort discussing with coworkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# p-value WITH DEMOGRAPHICS using Statsmodel Logistic Regression\n",
    "\n",
    "X_1 = independent_q1\n",
    "Y_1 = dep.values.astype(int)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_1)\n",
    "X_transformed_1 = scaler.transform(X_1)\n",
    "\n",
    "X_transformed_1 = np.hstack([np.ones([X_transformed_1.shape[0],1]), X_transformed_1])\n",
    "\n",
    "logit = sm.Logit(Y_1, X_transformed_1)\n",
    "fitted_model_demo = logit.fit_regularized()\n",
    "fitted_model_demo.summary()\n",
    "\n",
    "# alpha = 0.05\n",
    "# all features together are significant\n",
    "# Columns that are significant: 1,3,4,5,6,13,20,21,30,32,43,44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model to get the feature importances\n",
    "\n",
    "# filter depreciation warning that is associated with not using \n",
    "# the most updated version of numpy and scikit-learnin the vitual environment\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "ind_q1 = independent_q1.copy()\n",
    "ind_q1.columns = [np.arange(len(ind_q1.columns))]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ind_q1,dep.values.astype(int),test_size = 0.2)\n",
    "\n",
    "estimators = [(\"normalize\", preprocessing.StandardScaler()),\n",
    "             (\"model\",LogisticRegression())]\n",
    "\n",
    "pipe = pipeline.Pipeline(estimators)\n",
    "\n",
    "param_grid = [{\"model\":[XGBClassifier()], \n",
    "               \"normalize\": [preprocessing.StandardScaler(), preprocessing.MinMaxScaler(), None],\n",
    "               \"model__max_depth\":[1,2,3,4,5],\"model__n_estimators\":[50,100,150,200],\"model__n_jobs\":[6]},\n",
    "              {\"model\": [RandomForestClassifier()],\n",
    "               \"normalize\": [preprocessing.StandardScaler(), preprocessing.MinMaxScaler(), None],\n",
    "               \"model__n_estimators\":[100,150,200],\"model__n_jobs\":[6]}]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, n_jobs=6)\n",
    "fitted_grid_1 = grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_grid_1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_grid_1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_grid_1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score of the model\n",
    "y_pred = fitted_grid_1.predict(X_test)\n",
    "\n",
    "f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ranking of factors that are important for predicting comfort level, from most to least important\n",
    "indices = np.flip(fitted_grid_1.best_estimator_.named_steps[\"model\"].feature_importances_.argsort())\n",
    "\n",
    "# creating a list of factors that are statistically significant\n",
    "sig_list = [1,3,4,5,6,13,20,21,30,32,43,44]\n",
    "\n",
    "numbers = []\n",
    "for position,idx in enumerate(indices):\n",
    "    for num in sig_list:\n",
    "        if idx == num:\n",
    "            numbers.append(idx)\n",
    "\n",
    "independent_q1.columns[numbers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "#### b) Comfort discussing with supervisors\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2nd question regarding supervisors\n",
    "# p-value WITH DEMOGRAPHICS\n",
    "\n",
    "X_1 = independent_q1\n",
    "Y_1 = dep_2.values.astype(int)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_1)\n",
    "X_transformed_1 = scaler.transform(X_1)\n",
    "\n",
    "X_transformed_1 = np.hstack([np.ones([X_transformed_1.shape[0],1]), X_transformed_1])\n",
    "\n",
    "logit = sm.Logit(Y_1, X_transformed_1)\n",
    "fitted_model_demo = logit.fit_regularized()\n",
    "fitted_model_demo.summary()\n",
    "\n",
    "# alpha = 0.05\n",
    "# all features together are significant\n",
    "# Columns that are significant: 3,4,5,9,15,19,20,21,22,23,35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model to get the feature importances\n",
    "\n",
    "# filter depreciation warning that is associated with not using \n",
    "# the most updated version of numpy and scikit-learnin the vitual environment\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "ind_q1 = independent_q1.copy()\n",
    "ind_q1.columns = [np.arange(len(ind_q1.columns))]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ind_q1,dep_2.values.astype(int),test_size = 0.2)\n",
    "\n",
    "estimators = [(\"normalize\", preprocessing.StandardScaler()),\n",
    "             (\"model\",LogisticRegression())]\n",
    "\n",
    "pipe = pipeline.Pipeline(estimators)\n",
    "\n",
    "param_grid = [{\"model\":[XGBClassifier()], \n",
    "               \"normalize\": [preprocessing.StandardScaler(), preprocessing.MinMaxScaler(), None],\n",
    "               \"model__max_depth\":[1,2,3,4,5],\"model__n_estimators\":[50,100,150,200],\"model__n_jobs\":[6]},\n",
    "              {\"model\": [RandomForestClassifier()],\n",
    "               \"normalize\": [preprocessing.StandardScaler(), preprocessing.MinMaxScaler(), None],\n",
    "               \"model__n_estimators\":[100,150,200],\"model__n_jobs\":[6]}]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, n_jobs=6)\n",
    "fitted_grid_2 = grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_grid_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_grid_2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fitted_grid_2.predict(X_test)\n",
    "\n",
    "f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ranking of factors that are important for predicting comfort level, from most to least important\n",
    "indices = np.flip(fitted_grid_2.best_estimator_.named_steps[\"model\"].feature_importances_.argsort())\n",
    "\n",
    "# creating a list of factors that are statistically significant\n",
    "sig_list = [3,4,5,9,15,19,20,21,22,23,35]\n",
    "\n",
    "numbers = []\n",
    "for position,idx in enumerate(indices):\n",
    "    for num in sig_list:\n",
    "        if idx == num:\n",
    "            numbers.append(idx)\n",
    "\n",
    "independent_q1.columns[numbers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can companies to do encourage their employees to seek treatment?\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up 2 dataframes for concatenating data\n",
    "omitted = pd.DataFrame(columns = [\"Question\",\"Answer\"])\n",
    "final = pd.DataFrame()\n",
    "\n",
    "# current_mh_coverage\n",
    "for i in [0,2,3]:\n",
    "    result = make_dummies(current_mh_coverage[i],\"Yes\")\n",
    "    final = pd.concat([final,result],axis = 1)\n",
    "\n",
    "result = make_dummies_iloc(current_mh_coverage[5],[2,-2,-1])\n",
    "final = pd.concat([final,result],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a table of independend variables for this question\n",
    "ind_variable = pd.concat([final,demographics],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# determining statistical significance using statsmodel Logistic Regression\n",
    "dep_question = \"Have you ever sought treatment for a mental health disorder from a mental health professional?\"\n",
    "\n",
    "X_1 = ind_variable\n",
    "Y_1 = df_2.loc[:,dep_question]\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_1)\n",
    "X_transformed_1 = scaler.transform(X_1)\n",
    "\n",
    "X_transformed_1 = np.hstack([np.ones([X_transformed_1.shape[0],1]), X_transformed_1])\n",
    "\n",
    "logit = sm.Logit(Y_1, X_transformed_1)\n",
    "fitted_model_sp = logit.fit_regularized()\n",
    "fitted_model_sp.summary()\n",
    "\n",
    "# alpha = 0.05\n",
    "# all features together are significant\n",
    "# Columns that are significant: 0,5,6,7,8,12,14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model to get the feature importance\n",
    "ind_alt = ind_variable.copy()\n",
    "ind_alt.columns = [np.arange(len(ind_alt.columns))]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ind_alt,df_2.loc[:,dep_question],test_size = 0.2)\n",
    "\n",
    "estimators = [(\"normalize\", preprocessing.StandardScaler()),\n",
    "             (\"model\",LogisticRegression())]\n",
    "\n",
    "pipe = pipeline.Pipeline(estimators)\n",
    "\n",
    "param_grid = [{\"model\":[XGBClassifier()], \n",
    "               \"normalize\": [preprocessing.StandardScaler(), preprocessing.MinMaxScaler(), None],\n",
    "               \"model__max_depth\":[1,2,3,4,5],\"model__n_estimators\":[50,100,150,200],\"model__n_jobs\":[6]},\n",
    "              {\"model\": [RandomForestClassifier()],\n",
    "               \"normalize\": [preprocessing.StandardScaler(), preprocessing.MinMaxScaler(), None],\n",
    "               \"model__n_estimators\":[100,150,200],\"model__n_jobs\":[6]}]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "fitted_grid_3 = grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_grid_3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_grid_3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_grid_3.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fitted_grid_3.predict(X_test)\n",
    "\n",
    "f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking of factors that are important for predicting comfort level, from most to least important\n",
    "indices = np.flip(fitted_grid_3.best_estimator_.named_steps[\"model\"].feature_importances_.argsort())\n",
    "\n",
    "# displaying features that have statistical significance\n",
    "sig_list = [0,5,6,7,8,12,14]\n",
    "numbers = []\n",
    "for position,idx in enumerate(indices):\n",
    "    for num in sig_list:\n",
    "        if idx == num:\n",
    "            numbers.append(idx)\n",
    "\n",
    "ind_variable.columns[numbers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "### Can we predict one's comfort level in discussing MH at workplace using participants' qualitative responses of ways to improve MH support?\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the responses as independent variables\n",
    "corpus = df.iloc[:,-9]\n",
    "\n",
    "# Dependent variables\n",
    "question = \"Would you feel comfortable discussing a mental health issue with your coworkers?\"\n",
    "\n",
    "answers = [\"Maybe\",\"No\",\"Not Applicable\",\"Yes\"]\n",
    "\n",
    "dep = df[question].copy()\n",
    "\n",
    "for num in range(len(answers)):\n",
    "    if num != 3:\n",
    "        dep[dep==answers[num]] = 0 #Hesitant\n",
    "    else:\n",
    "        dep[dep==answers[num]] = 1 #Comfortable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Would you feel comfortable discussing a mental health issue with your coworkers?\n",
       "0    855\n",
       "1    318\n",
       "Name: Would you feel comfortable discussing a mental health issue with your coworkers?, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep.groupby(dep).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a table with both independent and dependent variables\n",
    "table = pd.concat([corpus,dep],axis=1)\n",
    "\n",
    "# dropping columns that did not answer the question\n",
    "index = table[table.iloc[:,0]==\"Did not answer\"].index\n",
    "table.drop(index,axis=0,inplace=True)\n",
    "\n",
    "# resetting the index\n",
    "table = table.reset_index()\n",
    "table.drop(\"index\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training/test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(table.iloc[:,0].values,\n",
    "                                                    table.iloc[:,1].values,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<631x949 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9550 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process and transform x_train\n",
    "\n",
    "# Lemmatization using SpaCy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# customizing stopwords to exclude certain stopwords\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "words = [\"against\",\"all\",\"aren't\",\"can't\",\"can\",\"cannot\",\"could\",\"couldn't\",\"did\",\n",
    "         \"didn't\",\"doing\",\"don't\",\"hasn't\",\"hadn't\",\"ever\",\"few\",\"mustn't\",\"once\",\"shan't\"]\n",
    "\n",
    "for word in words:\n",
    "    stopwords.remove(word)\n",
    "\n",
    "sentences = []\n",
    "\n",
    "for num in range(len(x_train)):\n",
    "    doc = nlp(x_train[num])\n",
    "\n",
    "    sentence = []\n",
    "    for token in doc:\n",
    "        sentence.append(token.lemma_)\n",
    "\n",
    "    sentences.append(\" \".join(sentence))\n",
    "\n",
    "# Processing text with TfidfVectorizer\n",
    "tf_model = TfidfVectorizer(stop_words=stopwords,ngram_range=(1,3), min_df=3)\n",
    "tf_vectors = tf_model.fit_transform(sentences); tf_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 451, 0: 451})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "sm = SMOTE(n_jobs = 6)\n",
    "X_res,y_res = sm.fit_resample(tf_vectors.toarray(),y_train)\n",
    "Counter(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<158x949 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1924 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process and transform x_test\n",
    "sentences = []\n",
    "\n",
    "for num in range(len(x_test)):\n",
    "    doc = nlp(x_test[num])\n",
    "\n",
    "    sentence = []\n",
    "    for token in doc:\n",
    "        sentence.append(token.lemma_)\n",
    "\n",
    "    sentences.append(\" \".join(sentence))\n",
    "\n",
    "x_test_vectors = tf_model.transform(sentences); x_test_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "estimators = [(\"normalize\", preprocessing.StandardScaler()),\n",
    "             (\"model\",LogisticRegression())]\n",
    "\n",
    "pipe = pipeline.Pipeline(estimators)\n",
    "\n",
    "param_grid = [{\"model\": [RandomForestClassifier()],\n",
    "               \"normalize\": [None],\"model__n_jobs\":[6]},\n",
    "              {\"model\": [GradientBoostingClassifier()],\"normalize\": [None]},\n",
    "              {\"model\":[LogisticRegression()],\"normalize\": [None]}]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "fitted_grid_3 = grid.fit(X_res,y_res.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_grid_3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_grid_3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_grid_3.score(x_test_vectors.toarray(),y_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fitted_grid_3.predict(x_test_vectors.toarray())\n",
    "\n",
    "f1_score(y_test.astype(int),y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=StackingCVClassifier(classifiers=[SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False), LogisticRegression(C=1.0, clas...           use_clones=True, use_features_in_secondary=False,\n",
       "           use_probas=False, verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'svc__kernel': ['rbf', 'poly', 'sigmoid'], 'randomforestclassifier__n_estimators': [50, 100], 'randomforestclassifier__n_jobs': [6], 'logisticregression__C': [0.0001, 0.01, 1, 10], 'logisticregression__penalty': ['l1', 'l2'], 'logisticregression__n_jobs': [6], 'meta-gradientboostingclassifier__n_estimators': [50, 100], 'meta-gradientboostingclassifier__max_depth': [3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "base_models = [SVC(), LogisticRegression(), RandomForestClassifier()]\n",
    "\n",
    "base_models = [(f'{model.__class__.__name__}-{i}', model) for i, model in enumerate(base_models)]\n",
    "\n",
    "stacked_model = StackingCVClassifier(classifiers=[model for _, model in base_models],\n",
    "                                     meta_classifier=GradientBoostingClassifier(), \n",
    "                                     use_features_in_secondary=False)\n",
    "\n",
    "params = {'svc__kernel': ['rbf','poly','sigmoid'],\n",
    "          'randomforestclassifier__n_estimators': [50,100],'randomforestclassifier__n_jobs': [6], \n",
    "          'logisticregression__C': [1e-4,1e-2,1,10],'logisticregression__penalty': ['l1','l2'],\n",
    "          'logisticregression__n_jobs': [6], 'meta-gradientboostingclassifier__n_estimators' : [50,100],\n",
    "          'meta-gradientboostingclassifier__max_depth': [3]}\n",
    "\n",
    "grid = GridSearchCV(estimator=stacked_model, param_grid=params, cv=3,refit=True)\n",
    "grid.fit(X_res, y_res.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8037694013303769"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1754385964912281"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = grid.predict(x_test_vectors.toarray())\n",
    "\n",
    "f1_score(y_test.astype(int),y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(64,activation=\"relu\", input_shape = (3,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    # setting up SGD (optimizer) hyperparameters\n",
    "    sgd = SGD(lr=0.0001, decay=0.0, momentum = 0.0, nesterov=False, clipnorm=2.0)\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = sgd, metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_models = [KNeighborsClassifier(),LogisticRegression(),\n",
    "               RandomForestClassifier()]\n",
    "\n",
    "base_models = [(f'{model.__class__.__name__}-{i}', model) for i, model in enumerate(base_models)]\n",
    "\n",
    "stacked_model = StackingCVClassifier(classifiers=[model for _, model in base_models],\n",
    "                                     meta_classifier=KerasClassifier(build_fn=NN_model, batch_size = 16, epochs = 4, validation_split = 0.2), \n",
    "                                     use_features_in_secondary=False)\n",
    "\n",
    "params = {'kneighborsclassifier__n_neighbors': [5,10,15],'kneighborsclassifier__n_jobs': [6],\n",
    "          'randomforestclassifier__n_estimators': [50,100],'randomforestclassifier__class_weight': [\"balanced\"],\n",
    "          'randomforestclassifier__n_jobs': [6], 'logisticregression__C': [1e-4,1e-2,1,10],\n",
    "          'logisticregression__penalty': ['l1','l2'],'logisticregression__n_jobs': [6]}\n",
    "\n",
    "grid = GridSearchCV(estimator=stacked_model, param_grid=params, cv=3,refit=True)\n",
    "grid.fit(X_res, y_res.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict(x_test_vectors.toarray())\n",
    "\n",
    "f1_score(y_test.astype(int),y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input an response and see if the model predicts correctly\n",
    "response = input(\"Briefly describe what you think the tech industry as a whole and/or \\\n",
    "employers could do to improve mental health support for employees.\")\n",
    "\n",
    "print(\"Processing...\")\n",
    "\n",
    "# Text processing to prepare data for RNN\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "sentences = []\n",
    "doc = nlp(response)\n",
    "\n",
    "sentence = []\n",
    "for token in doc:\n",
    "    sentence.append(token.lemma_)\n",
    "\n",
    "sentences.append(\" \".join(sentence))\n",
    "\n",
    "print(\"Almost there...\")\n",
    "\n",
    "# Processing text with TfidfVectorizer\n",
    "tf_vectors = tf_model.transform(sentences)\n",
    "\n",
    "# predicting the result using the model\n",
    "y_pred = grid.predict(tf_vectors.toarray())\n",
    "y_pred\n",
    "# # printing the result\n",
    "# if y_pred[0][0] > 0.5:\n",
    "#     print(\"The model predicts you are hesitant with discussing MH issue with your coworkers.\")\n",
    "# else:\n",
    "#     print(\"The model predicts you to have comfortable with discussing MH issue with your coworkers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
